{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of MNIST Digits with SVD Decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task for this exercise is to learn the classification of MNIST digits by using SVD decomposition.  \n",
    "  \n",
    "Remember that, Given a matrix X ∈ R m×n and its SVD decomposition X = USV.T we can prove that an orthogonal base for the space of the columns is given by the first p columns of the matrix U , where p = rank(X) is equal to the number of non-zero singular values of A.  \n",
    "  \n",
    "The approach is to find orthogonal projection of a test data into a subspace of X1 (or X2 or Xn) which is generated by columns of U1 (or U2 or Un). Then we calculate the projection error on each subspace and due to the minimum error we decide to put the test data into specific classifier. U1 (or Un) is the subspace related to the X columns which represents the digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "  \n",
    " first implement the classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classifier(digits, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Generate the matrices X0, X1\n",
    "    X1 = X_train[:,y_train == digits[0]]\n",
    "    X2 = X_train[:,y_train == digits[1]]\n",
    "\n",
    "    # Compute the SVD decomposition of X0 and X1\n",
    "    U1, _, _ = np.linalg.svd(X1, full_matrices=False)\n",
    "    U2, _, _ = np.linalg.svd(X2, full_matrices=False)\n",
    "\n",
    "    n_true = 0\n",
    "    # Take a new, unknown digit for the test set.\n",
    "    for i in range(len(y_test)):\n",
    "        y = X_test[:,i]\n",
    "\n",
    "        # Compute the projections of y into the two spaces\n",
    "        y_1 = U1 @ (U1.T @ y)\n",
    "        y_2 = U2 @ (U2.T @ y)\n",
    "\n",
    "        # Compute the distances\n",
    "        d_1 = np.linalg.norm(y - y_1)\n",
    "        d_2 = np.linalg.norm(y - y_2)\n",
    "\n",
    "        # Assign to the predicted class\n",
    "        if d_1 < d_2:\n",
    "            predicted_class = digits[0]\n",
    "        else:\n",
    "            predicted_class = digits[1]\n",
    "\n",
    "        # computing the number of true classification\n",
    "        if(predicted_class == y_test[i]):\n",
    "            n_true += 1\n",
    "\n",
    "    # computing the accuracy of the classification\n",
    "    return n_true/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 1:** If X1 is full rank: means we can create all the other 16x16 matrices using linear combination of X1 vectors. but since the numbers have different features (for example features of number 1 and 8), it is not possible.  \n",
    "\t\n",
    "**Note 2:** By choosing *\"full_matrices=False\"* in SVD decomposition, we obtain only r columns of U (r = rank(X)). if U1 is a considered full rank (considering all the columns of U) then the subspace y_1 would be equal to y."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
